Cyara is looking for a solution to reduce compute costs associated with customer load tests without impacting performance of scheduled testing.

The simplest solution would be to use an EC2 autoscaling group using a dynamic scaling policy that keys off of either cpu or memory metrics depending on what is the more limiting factor.  Warm up and cool down values can be adjusted accordingly to make the autoscaling response more sensitive to increases and decreases in demand.  

But the problem as presented mentions a booking API that can be called to get the details of scheduled load tests so in the spirit of exploring other options and maybe over architecting things I've created a diagram to discuss a more complex solution.

My proposal is to build an ec2 autoscaling group that hosts the application performing the load tests and use a custom lambda script that queries the booking api to calculate the number of customers with scheduled load tests and creates a scheduled update of the ASG at predetermined intervals to accomodate the anticipated load.  The lambda can be scheduled to run with AWS event bridge and can use SNS to send out notifications such as what scheduled actions have been created or warnings about issues with the script.  Examples of things to code for would be a number of instances calculated as required exceeding max size for the ASG, failure to retreive data from the api call, and errors running the autoscaling put-scheduled-update-group-action command.  Another limitation to consider with this proposed solution is the limit of 125 scheduled actions per autoscaling group which would mean scaling would be limited to adjustments every 15 minutes.
